# COS-802-Machine-Translation-Model-PROJECT
# African Machine Translation Evaluation: Impact of Data Quality

##ðŸ“Œ Project Overview

Machine translation models for low-resource African languages are often evaluated against benchmarks that contain significant errors. This project investigates the impact of dataset corrections on the FLORES-200 benchmark for four African languages: Hausa (hau), Sepedi (nso), Xitsonga (tso), and isiZulu (zul).

Using a "before-and-after" comparative methodology, this study evaluates two state-of-the-art models (NLLB-200 and M2M-100) to determine how fixing the test data influences:

Translation Quality Scores (BLEU, ChrF, BERTScore, COMET).

Model Performance Ranking.

Interpretability and Error Diagnosis.
